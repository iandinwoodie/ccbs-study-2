---
title: "Statistical Inference - Logistic Regression"
author: "Ian Dinwoodie"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(tidymodels)
library(car)
library(MASS)
library(caret)
library(boot)
#library(broom)
library(rpart)
library(rpart.plot)
#library(qvalue)
knitr::opts_chunk$set(echo=TRUE)
set.seed(1)
```

# Preparing the Data

## Loading the Tidy Data

Load the tidy data from disk.

```{r}
df <- readRDS('../data/processed/tidy.Rds')
#stopifnot(identical(dim(df)+0, c(1543, 28)))
str(df, list.len=5)
```

## Data Preperation

Drop columns that won't be used by the inferential models.

```{r}
df <- df %>%
  dplyr::select(-c(
    owner_id,
    dog_name,
    time_together_len,
    revised_acquisition_source,
    #is_living_with_dog,
    curr_dog_location,
    met_expectations,
    is_consider_another_dog
  )) %>%
  dplyr::select(-contains("revised"))

dim(df)
summary(df)
```

Remove problematic variables and rows with missing values.

```{r}
df <- df %>%
  #dplyr::select(-trainability_rank) %>%
  #dplyr::select(-is_male) %>%
  mutate(is_satisfied = as.factor(is_satisfied)) %>%
  #mutate(is_satisfied = as.factor(ifelse(is_satisfied, "yes", "no"))) %>%
  drop_na()
```

```{r}
binary_sig_table <- function(model) {
  df_results <- broom::tidy(model, conf.int=TRUE, exponentiate=TRUE)
  df_results$p.value <- p.adjust(df_results$p.value, method='BH')
  #df_results$p.value <- qvalue(df_results$p.value)$qvalues
  df_results$sig <- ''
  df_results[df_results$p.value <= .05, 'sig'] <- '*'
  df_results[df_results$p.value <= .01, 'sig'] <- '**'
  df_results[df_results$p.value <= .001, 'sig'] <- '***'
  for (i in 1:nrow(df_results)) {
    if (is.na(df_results[i, 'conf.low']) | is.na(df_results[i, 'conf.high'])) next
    if ((df_results[i, 'conf.low'] < 1) & (df_results[i, 'conf.high'] > 1)) {
      df_results[i, 'sig'] <- ''
    }
  }
  knitr::kable(df_results)
}
```

# Univariate Tests

```{r}
p_values <- NULL
(test <- wilcox.test(df$age_rank ~ df$is_satisfied))
p_values <- cbind(p_values, test$p.value)

(test <- wilcox.test(df$appearance_rank ~ df$is_satisfied))
p_values <- cbind(p_values, test$p.value)

(test <- wilcox.test(df$breed_rank ~ df$is_satisfied))
p_values <- cbind(p_values, test$p.value)

(test <- wilcox.test(df$compatability_rank ~ df$is_satisfied))
p_values <- cbind(p_values, test$p.value)

(test <- wilcox.test(df$personality_rank ~ df$is_satisfied))
p_values <- cbind(p_values, test$p.value)

(test <- wilcox.test(df$size_rank ~ df$is_satisfied))
p_values <- cbind(p_values, test$p.value)

(test <- wilcox.test(df$trainability_rank ~ df$is_satisfied))
p_values <- cbind(p_values, test$p.value)

(p_values)
p.adjust(p_values, method="bonferroni")
```

(Optional) Convert the ranks from numeric to ordered factor.

```{r}
rank_cols = c("age_rank", "appearance_rank", "breed_rank", "compatability_rank",
              "personality_rank", "size_rank", "trainability_rank")
#df <- df %>% mutate_at(rank_cols, ordered)
```

```{r}
df <- df %>%
  dplyr::select(-c(
    age_rank,
    appearance_rank,
    breed_rank,
    compatability_rank,
    size_rank,
    trainability_rank
  ))
```

# Binary Logistic Regression

## Preprocessing

```{r}
mm <- model.matrix(is_satisfied~.-1, df)
str(mm)
```

```{r}
# Eliminate near zero-variance variables.
(nzv_metrics <- nearZeroVar(mm, saveMetrics=TRUE))
nzv_cnt <- sum(nzv_metrics$nzv)
print(paste("Near zero-variance vars to eliminate:", nzv_cnt))
if (nzv_cnt) {
  print(colnames(mm[, nzv_metrics$nzv]))
  mm <- mm[, !nzv_metrics$nzv]
}

# Eliminate linearly correlated predictors.
combo_info <- findLinearCombos(mm)
combo_cnt <- length(combo_info$remove)
print(paste("Linearly corr. combos vars to eliminate:", combo_cnt))
if (combo_cnt) {
  print(colnames(mm[, combo_info$remove]))
  mm <- mm[, -combo_info$remove]
}
```

```{r}
df <- cbind.data.frame(is_satisfied=df$is_satisfied, mm)
colnames(df) <- make.names(colnames(df))
dim(df)
summary(df)
```

## Data Partitions

Partition the data into training and testing sets.

```{r}
set.seed(1)
in_train <- createDataPartition(
  y = df$is_satisfied,
  p = .7,
  list = FALSE
)
training <- df[in_train,]
summary(training$is_satisfied)
testing <- df[-in_train,]
summary(testing$is_satisfied)
```

## Fitting Model

```{r}
set.seed(500)
glm_fit <- glm(is_satisfied~.-1, data=df, family="binomial")
summary(glm_fit)
```

```{r}
binary_sig_table(glm_fit)
```

```{r}
glm_est <- function(split, ...) {
  glm(glm_fit$formula, data = analysis(split), family="binomial") %>%
    tidy()
}

#set.seed(1) #500
#set.seed(500)
set.seed(1)
conf_ints <- bootstraps(df, 1000, apparent = TRUE) %>%
  mutate(results = map(splits, glm_est)) %>%
  int_bca(results, .fn = glm_est) %>%
  mutate_at(c(".estimate", ".lower", ".upper"), ~ exp(.))
(conf_ints)
```

```{r}
confusionMatrix(predict(glm_fit, df), df$is_satisfied)
```

# OLD CODE BELOW

```{r}
stopifnot(FALSE)
```

### Age Rank

```{r}
set.seed(1)
glm_fit <- glm(is_satisfied~., df[,-c(14:19)], family="bonferroni") #family="binomial")
summary(glm_fit)
```

### Appearance Rank

```{r}
set.seed(1)
glm_fit <- glm(is_satisfied~., df[,-c(13,15:19)], family="binomial")
summary(glm_fit)
```

### Breed Rank

```{r}
set.seed(1)
glm_fit <- glm(is_satisfied~., df[,-c(13:14, 16:19)], family="binomial")
summary(glm_fit)
```

### Compatability Rank

```{r}
set.seed(1)
glm_fit <- glm(is_satisfied~., df[,-c(13:15, 17:19)], family="binomial")
summary(glm_fit)
```

### Personality Rank

```{r}
set.seed(1)
df_glm <- df[,-c(13:16, 18:19)]
glm_fit <- glm(is_satisfied~., df_glm, family="binomial")
summary(glm_fit)
```

```{r}
glm_est <- function(split, ...) {
  glm(glm_fit$formula, data = analysis(split), family="binomial") %>%
    tidy()
}

#set.seed(1) #500
#set.seed(500)
set.seed(1)
conf_ints <- bootstraps(df_glm, 100, apparent = TRUE) %>%
  mutate(results = map(splits, glm_est)) %>%
  int_bca(results, .fn = glm_est) %>%
  mutate_at(c(".estimate", ".lower", ".upper"), ~ exp(.))
(conf_ints)
```

### Size Rank

```{r}
set.seed(1)
glm_fit <- glm(is_satisfied~., df[,-c(13:17, 19)], family="binomial")
summary(glm_fit)
```

### Trainability Rank

```{r}
set.seed(1)
glm_fit <- glm(is_satisfied~., df[,-c(13:18)], family="binomial")
summary(glm_fit)
```

### No Rank

```{r}
set.seed(1)
glm_fit <- glm(is_satisfied~., df[,-c(13:19)], family="binomial")
summary(glm_fit)
```

# Save Session Info

```{r}
sessionInfo()
```
