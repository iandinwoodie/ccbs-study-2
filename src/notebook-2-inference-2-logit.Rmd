---
title: "Statistical Inference - Logistic Regression"
author: "Ian Dinwoodie"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(tidymodels)
library(car)
library(MASS)
library(caret)
library(boot)
#library(broom)
#library(rpart)
#library(rpart.plot)
library(qvalue)
knitr::opts_chunk$set(echo=TRUE)
set.seed(1)
```

# Preparing the Data

## Loading the Tidy Data

Load the tidy data from disk.

```{r}
df <- readRDS('../data/processed/tidy.Rds')
stopifnot(identical(dim(df)+0, c(1543, 28)))
str(df, list.len=5)
```

## Drop Unnecessary Columns

Here we drop columns that won't be used by any of the inferential models.

```{r}
df <- df %>%
  dplyr::select(-c(
    owner_id,
    dog_name,
    time_together_len,
    revised_acquisition_source,
    curr_dog_location
  )) %>%
  dplyr::select(-contains("revised"))

summary(df)
```

# Initialize Shared Functions

```{r}
binary_sig_table <- function(model) {
  df_results <- broom::tidy(model, conf.int=TRUE, exponentiate=TRUE)
  #df_results$p.value <- p.adjust(df_results$p.value, method='fdr')
  df_results$p.value <- qvalue(df_results$p.value)$qvalues
  df_results$sig <- ''
  df_results[df_results$p.value <= .05, 'sig'] <- '*'
  df_results[df_results$p.value <= .01, 'sig'] <- '**'
  df_results[df_results$p.value <= .001, 'sig'] <- '***'
  for (i in 1:nrow(df_results)) {
    if (is.na(df_results[i, 'conf.low']) | is.na(df_results[i, 'conf.high'])) next
    if ((df_results[i, 'conf.low'] < 1) & (df_results[i, 'conf.high'] > 1)) {
      df_results[i, 'sig'] <- ''
    }
  }
  knitr::kable(df_results)
}
```

# Binary Logistic Regression

```{r}
df <- df %>%
  rowwise() %>%
    mutate(rank_sum = sum(c_across(age_rank:trainability_rank))) %>%
  ungroup() %>%
  filter(rank_sum == 28) %>%
  dplyr::select(-rank_sum)
```

```{r}
# char_map = c(
#   "Age"="age_rank",
#   "Appearance"="appearance_rank",
#   "Breed"="breed_rank",
#   "Compatability with other pets in the home"="compatability_rank",
#   "Individual personality/behavior"="personality_rank",
#   "Size"="size_rank",
#   "Trainability"="trainability_rank"
# )
# df <- df %>% mutate_at(as.vector(char_map), ordered)
```

```{r}
df <- df %>%
  dplyr::select(-met_expectations) %>%
  dplyr::select(-is_living_with_dog) %>%
  dplyr::select(-is_consider_another_dog) %>%
  dplyr::select(-trainability_rank) %>%
  dplyr::select(-is_male) %>%
  mutate(is_satisfied = as.factor(is_satisfied)) %>%
  #mutate(is_satisfied = as.factor(ifelse(is_satisfied, "yes", "no"))) %>%
  drop_na()

dim(df)
summary(df)
```

## Matrix Model

```{r}
mm <- model.matrix(is_satisfied~.-1, df)
(nzv <- nearZeroVar(mm, saveMetrics=TRUE))
if (length(nzv$nzv)) {
  mm <- mm[, !nzv$nzv]
}
```

```{r}
(comboInfo <- findLinearCombos(mm))
#mm <- mm[, -comboInfo$remove]
```

```{r}
set.seed(1)
# define training control
train_control <- trainControl(method = "boot", number = 10)

# train the model on training set
#model <- train(x=mm, y=df$is_satisfied,
df_mm = as.data.frame(mm)
df_mm["is_satisfied"] = df$is_satisfied
model <- train(is_satisfied~., data=df_mm,
               trControl = train_control,
               method = "glm",
               family=binomial())

# print cv scores
summary(model)
```

```{r}
final_model <- model$finalModel
(df_model <- tidy(final_model))
```

```{r}
p.adjust(df_model$p.value, method='fdr')
```

```{r}
set.seed(2154)
qvalue(df_model$p.value, lambda = seq(0.05, 0.95, 0.05), pi0 = 0.1)
```

```{r}
glance(final_model)
```



```{r}
(bs)
bs$t0
#bs$t0[2] - (2*0.0587861006)
#bs$t0[2] + (2*0.0587861006)
bs$t0[5] - (2*0.0266116007)
bs$t0[5] + (2*0.0266116007)
```


```{r}
df_results <- broom::tidy(model$finalModel, conf.int=TRUE, exponentiate=TRUE)
#df_results$p.value <- p.adjust(df_results$p.value, method='fdr')
#df_results$p.value <- qvalue(df_results$p.value)$qvalues
df_results$sig <- ''
df_results[df_results$p.value <= .05, 'sig'] <- '*'
df_results[df_results$p.value <= .01, 'sig'] <- '**'
df_results[df_results$p.value <= .001, 'sig'] <- '***'
for (i in 1:nrow(df_results)) {
  if (is.na(df_results[i, 'conf.low']) | is.na(df_results[i, 'conf.high'])) next
  if ((df_results[i, 'conf.low'] < 1) & (df_results[i, 'conf.high'] > 1)) {
    df_results[i, 'sig'] <- ''
  }
}
knitr::kable(df_results)
```

## Dummy Vars Tibble

```{r}
# dummies <- dummyVars(~., data = df %>% select(-is_satisfied))
# tib <- as_tibble(predict(dummies, newdata = df))
# tib <- cbind(is_satisfied=df$is_satisfied, tib)
# summary(tib)
```

```{r}
# # Eliminate near zero-variance predictors.
# (nzv <- nearZeroVar(tib, saveMetrics=TRUE))
# if (length(nzv$nzv)) {
#   tib <- tib[, !nzv$nzv]
# }
```

```{r}
#(cor_matrix <- cor(tib))
# highCorr <- sum(abs(cor_matrix[upper.tri(cor_matrix)]) > .7)
# print(highCorr)
```

# OLD BELOW THIS LINE

```{r}
stopifnot(FALSE)
```

```{r}

#dummies <- dummyVars(is_satisfied ~ ., data = df)
#head(predict(dummies, newdata = df))
#nearZeroVar(predict(dummies, newdata = df), saveMetrics=TRUE)
```

```{r}
#mm <- model.matrix(is_satisfied~.-1, df)
#(nzv <- nearZeroVar(mm, saveMetrics=TRUE))
#mm <- mm[, !nzv$nzv]
```


```{r}
# Eliminate near zero-variance predictors.
#(nzv <- nearZeroVar(df, freqCut = 90/10, saveMetrics=TRUE))
#df <- df[, !nzv$nzv]
```

```{r}
# cor_matrix <- cor(mm)
# highCorr <- sum(abs(cor_matrix[upper.tri(cor_matrix)]) > .7)
# print(highCorr)
# 
# highlyCorDescr <- findCorrelation(cor_matrix, cutoff = .7)
# colnames(mm)[highlyCorDescr]
# mm2 <- mm[,-highlyCorDescr]
# descrCor2 <- cor(mm2)
# summary(descrCor2[upper.tri(descrCor2)])
# 
# summary(mm)
# summary(mm2)
```

```{r}
(comboInfo <- findLinearCombos(mm))
#mm <- mm[, -comboInfo$remove]
```

```{r}
set.seed(1)
# define training control
train_control <- trainControl(method = "boot", number = 5000)

# train the model on training set
model <- train(x=mm, y=df$is_satisfied,
               trControl = train_control,
               method = "glm",
               family=binomial())

# print cv scores
summary(model)
```

```{r}
df_results <- broom::tidy(model$finalModel, conf.int=TRUE, exponentiate=TRUE)
#df_results$p.value <- p.adjust(df_results$p.value, method='fdr')
#df_results$p.value <- qvalue(df_results$p.value)$qvalues
df_results$sig <- ''
df_results[df_results$p.value <= .05, 'sig'] <- '*'
df_results[df_results$p.value <= .01, 'sig'] <- '**'
df_results[df_results$p.value <= .001, 'sig'] <- '***'
for (i in 1:nrow(df_results)) {
  if (is.na(df_results[i, 'conf.low']) | is.na(df_results[i, 'conf.high'])) next
  if ((df_results[i, 'conf.low'] < 1) & (df_results[i, 'conf.high'] > 1)) {
    df_results[i, 'sig'] <- ''
  }
}
knitr::kable(df_results)
```

## Full Data Training

### All Parameters

```{r}
set.seed(1)
m_binary <- glm(is_satisfied~., data=mm, family="binomial")
summary(m_binary)
print(vif(m_binary))
```

```{r}
binary_sig_table(m_binary)
```

### AIC Stepwise Model Selection

```{r}
set.seed(1)
m_binary_aic <- stepAIC(m_binary, direction="both", trace=FALSE)
#m_binary_aic$anova
summary(m_binary_aic)
```

```{r}
binary_sig_table(m_binary_aic)
```

### Cross Validation

```{r}
set.seed(1)
# define training control
train_control <- trainControl(method = "cv", number = 10)

# train the model on training set
model <- train(is_satisfied~.,
               data = df,
               trControl = train_control,
               method = "glm",
               family=binomial())

# print cv scores
summary(model)
```

```{r}
df_results <- broom::tidy(model$finalModel, conf.int=TRUE, exponentiate=TRUE)
df_results$p.value <- p.adjust(df_results$p.value, method='fdr')
df_results$sig <- ''
df_results[df_results$p.value <= .05, 'sig'] <- '*'
df_results[df_results$p.value <= .01, 'sig'] <- '**'
df_results[df_results$p.value <= .001, 'sig'] <- '***'
for (i in 1:nrow(df_results)) {
  if (is.na(df_results[i, 'conf.low']) | is.na(df_results[i, 'conf.high'])) next
  if ((df_results[i, 'conf.low'] < 1) & (df_results[i, 'conf.high'] > 1)) {
    df_results[i, 'sig'] <- ''
  }
}
knitr::kable(df_results)
```

## Split Data Training

### All Parameters

```{r}
# Split into training and test data.
set.seed(666)
training.samples <- df$age %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data  <- df[training.samples, ]
test.data <- df[-training.samples, ]

# cols = c('age', 'age_rank', 'appearance_rank', 'breed_rank',
#          'compatability_rank', 'personality_rank', 'size_rank')
# pre_proc_val <- preProcess(train.data[,cols], method = c("center", "scale"))
# train.data[,cols] = predict(pre_proc_val, train.data[,cols])
# test.data[,cols] = predict(pre_proc_val, test.data[,cols])
# summary(train.data)
```

```{r}
set.seed(1)
m_binary <- glm(is_satisfied~., data=train.data, family="binomial")
summary(m_binary)

print(vif(m_binary))
```

```{r}
binary_sig_table(m_binary)
```

### Stepwise Model Selection

```{r}
set.seed(1)
m_binary_aic <- stepAIC(m_binary, direction="both", trace=FALSE)
#m_binary_aic$anova
summary(m_binary_aic)
```

```{r}
binary_sig_table(m_binary_aic)
```

```{r}
fit <- rpart(is_satisfied~., method="class", data=df, control=rpart.control(minsplit=2, minbucket=1, cp=0.0075))
rpart.plot(fit)
```


# Save Session Info

```{r}
sessionInfo()
```
